{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import SGD\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 参数\n",
    "batch_size=128\n",
    "n_classes=10\n",
    "n_epoch=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载MNIST数据集\n",
    "(X_train,y_train),(X_test,y_test)=mnist.load_data()\n",
    "X_train=X_train.reshape(60000,784)\n",
    "X_test=X_test.reshape(10000,784)\n",
    "X_train=X_train.astype('float32')\n",
    "X_test=X_test.astype('float32')\n",
    "X_train/=255\n",
    "X_test/=255\n",
    "y_train=np_utils.to_categorical(y_train,num_classes=n_classes)\n",
    "y_test=np_utils.to_categorical(y_test,num_classes=n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_13 (Dense)             (None, 625)               490625    \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 625)               391250    \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 10)                6260      \n",
      "=================================================================\n",
      "Total params: 888,135\n",
      "Trainable params: 888,135\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 多层感知机模型\n",
    "model=Sequential()\n",
    "model.add(Dense(input_dim=784,units=625,kernel_initializer='normal',activation='sigmoid'))\n",
    "model.add(Dense(input_dim=625,units=625,kernel_initializer='normal',activation='sigmoid'))\n",
    "model.add(Dense(input_dim=625,units=10,kernel_initializer='normal',activation='softmax'))\n",
    "model.compile(optimizer=SGD(lr=0.05),loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/100\n",
      "48000/48000 [==============================] - 3s 70us/step - loss: 2.0403 - acc: 0.3579 - val_loss: 1.6295 - val_acc: 0.5036\n",
      "Epoch 2/100\n",
      "48000/48000 [==============================] - 1s 30us/step - loss: 1.1684 - acc: 0.7253 - val_loss: 0.8170 - val_acc: 0.7929\n",
      "Epoch 3/100\n",
      "48000/48000 [==============================] - 1s 28us/step - loss: 0.7038 - acc: 0.8253 - val_loss: 0.5653 - val_acc: 0.8578\n",
      "Epoch 4/100\n",
      "48000/48000 [==============================] - 1s 28us/step - loss: 0.5423 - acc: 0.8566 - val_loss: 0.4794 - val_acc: 0.8686\n",
      "Epoch 5/100\n",
      "48000/48000 [==============================] - 1s 29us/step - loss: 0.4684 - acc: 0.8734 - val_loss: 0.4178 - val_acc: 0.8869\n",
      "Epoch 6/100\n",
      "48000/48000 [==============================] - 1s 27us/step - loss: 0.4245 - acc: 0.8820 - val_loss: 0.3828 - val_acc: 0.8954\n",
      "Epoch 7/100\n",
      "48000/48000 [==============================] - 1s 27us/step - loss: 0.3971 - acc: 0.8895 - val_loss: 0.3585 - val_acc: 0.8988\n",
      "Epoch 8/100\n",
      "48000/48000 [==============================] - 1s 29us/step - loss: 0.3776 - acc: 0.8922 - val_loss: 0.3451 - val_acc: 0.9007\n",
      "Epoch 9/100\n",
      "48000/48000 [==============================] - 1s 26us/step - loss: 0.3642 - acc: 0.8955 - val_loss: 0.3414 - val_acc: 0.9034\n",
      "Epoch 10/100\n",
      "48000/48000 [==============================] - 1s 27us/step - loss: 0.3529 - acc: 0.8988 - val_loss: 0.3291 - val_acc: 0.9029\n",
      "Epoch 11/100\n",
      "48000/48000 [==============================] - 2s 34us/step - loss: 0.3441 - acc: 0.9002 - val_loss: 0.3231 - val_acc: 0.9058\n",
      "Epoch 12/100\n",
      "48000/48000 [==============================] - 2s 34us/step - loss: 0.3362 - acc: 0.9034 - val_loss: 0.3155 - val_acc: 0.9065\n",
      "Epoch 13/100\n",
      "48000/48000 [==============================] - 1s 28us/step - loss: 0.3292 - acc: 0.9045 - val_loss: 0.3065 - val_acc: 0.9107\n",
      "Epoch 14/100\n",
      "48000/48000 [==============================] - 1s 28us/step - loss: 0.3236 - acc: 0.9069 - val_loss: 0.3027 - val_acc: 0.9112\n",
      "Epoch 15/100\n",
      "48000/48000 [==============================] - 2s 35us/step - loss: 0.3183 - acc: 0.9076 - val_loss: 0.2955 - val_acc: 0.9146\n",
      "Epoch 16/100\n",
      "48000/48000 [==============================] - 2s 36us/step - loss: 0.3140 - acc: 0.9095 - val_loss: 0.2946 - val_acc: 0.9135\n",
      "Epoch 17/100\n",
      "48000/48000 [==============================] - 1s 28us/step - loss: 0.3094 - acc: 0.9103 - val_loss: 0.2881 - val_acc: 0.9166\n",
      "Epoch 18/100\n",
      "48000/48000 [==============================] - 1s 27us/step - loss: 0.3059 - acc: 0.9108 - val_loss: 0.2931 - val_acc: 0.9155\n",
      "Epoch 19/100\n",
      "48000/48000 [==============================] - 1s 29us/step - loss: 0.3022 - acc: 0.9129 - val_loss: 0.2846 - val_acc: 0.9183\n",
      "Epoch 20/100\n",
      "48000/48000 [==============================] - 1s 31us/step - loss: 0.2990 - acc: 0.9137 - val_loss: 0.2820 - val_acc: 0.9188\n",
      "Epoch 21/100\n",
      "48000/48000 [==============================] - 1s 29us/step - loss: 0.2954 - acc: 0.9144 - val_loss: 0.2795 - val_acc: 0.9190\n",
      "Epoch 22/100\n",
      "48000/48000 [==============================] - 1s 28us/step - loss: 0.2929 - acc: 0.9150 - val_loss: 0.2750 - val_acc: 0.9212\n",
      "Epoch 23/100\n",
      "48000/48000 [==============================] - 1s 27us/step - loss: 0.2897 - acc: 0.9159 - val_loss: 0.2776 - val_acc: 0.9195\n",
      "Epoch 24/100\n",
      "48000/48000 [==============================] - 1s 29us/step - loss: 0.2867 - acc: 0.9168 - val_loss: 0.2738 - val_acc: 0.9207\n",
      "Epoch 25/100\n",
      "48000/48000 [==============================] - 1s 27us/step - loss: 0.2839 - acc: 0.9180 - val_loss: 0.2706 - val_acc: 0.9231\n",
      "Epoch 26/100\n",
      "48000/48000 [==============================] - 1s 31us/step - loss: 0.2819 - acc: 0.9174 - val_loss: 0.2715 - val_acc: 0.9219\n",
      "Epoch 27/100\n",
      "48000/48000 [==============================] - 1s 31us/step - loss: 0.2793 - acc: 0.9191 - val_loss: 0.2658 - val_acc: 0.9237\n",
      "Epoch 28/100\n",
      "48000/48000 [==============================] - 1s 31us/step - loss: 0.2771 - acc: 0.9198 - val_loss: 0.2661 - val_acc: 0.9248\n",
      "Epoch 29/100\n",
      "48000/48000 [==============================] - 1s 29us/step - loss: 0.2746 - acc: 0.9211 - val_loss: 0.2617 - val_acc: 0.9267\n",
      "Epoch 30/100\n",
      "48000/48000 [==============================] - 1s 29us/step - loss: 0.2717 - acc: 0.9214 - val_loss: 0.2702 - val_acc: 0.9226\n",
      "Epoch 31/100\n",
      "48000/48000 [==============================] - 1s 26us/step - loss: 0.2699 - acc: 0.9220 - val_loss: 0.2578 - val_acc: 0.9253\n",
      "Epoch 32/100\n",
      "48000/48000 [==============================] - 1s 29us/step - loss: 0.2675 - acc: 0.9228 - val_loss: 0.2639 - val_acc: 0.9233\n",
      "Epoch 33/100\n",
      "48000/48000 [==============================] - 1s 27us/step - loss: 0.2654 - acc: 0.9234 - val_loss: 0.2570 - val_acc: 0.9258\n",
      "Epoch 34/100\n",
      "48000/48000 [==============================] - 2s 32us/step - loss: 0.2627 - acc: 0.9238 - val_loss: 0.2525 - val_acc: 0.9270\n",
      "Epoch 35/100\n",
      "48000/48000 [==============================] - 2s 35us/step - loss: 0.2611 - acc: 0.9249 - val_loss: 0.2555 - val_acc: 0.9271\n",
      "Epoch 36/100\n",
      "48000/48000 [==============================] - 1s 27us/step - loss: 0.2586 - acc: 0.9253 - val_loss: 0.2506 - val_acc: 0.9281\n",
      "Epoch 37/100\n",
      "48000/48000 [==============================] - 1s 28us/step - loss: 0.2562 - acc: 0.9261 - val_loss: 0.2538 - val_acc: 0.9256\n",
      "Epoch 38/100\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 0.2546 - acc: 0.9265 - val_loss: 0.2493 - val_acc: 0.9286\n",
      "Epoch 39/100\n",
      "48000/48000 [==============================] - 2s 34us/step - loss: 0.2515 - acc: 0.9270 - val_loss: 0.2465 - val_acc: 0.9291\n",
      "Epoch 40/100\n",
      "48000/48000 [==============================] - 1s 30us/step - loss: 0.2498 - acc: 0.9278 - val_loss: 0.2425 - val_acc: 0.9303\n",
      "Epoch 41/100\n",
      "48000/48000 [==============================] - 1s 28us/step - loss: 0.2475 - acc: 0.9286 - val_loss: 0.2398 - val_acc: 0.9321\n",
      "Epoch 42/100\n",
      "48000/48000 [==============================] - 1s 27us/step - loss: 0.2455 - acc: 0.9289 - val_loss: 0.2413 - val_acc: 0.9311\n",
      "Epoch 43/100\n",
      "48000/48000 [==============================] - 1s 26us/step - loss: 0.2431 - acc: 0.9294 - val_loss: 0.2371 - val_acc: 0.9334\n",
      "Epoch 44/100\n",
      "48000/48000 [==============================] - 1s 25us/step - loss: 0.2405 - acc: 0.9307 - val_loss: 0.2385 - val_acc: 0.9306\n",
      "Epoch 45/100\n",
      "48000/48000 [==============================] - 1s 25us/step - loss: 0.2381 - acc: 0.9307 - val_loss: 0.2327 - val_acc: 0.9339\n",
      "Epoch 46/100\n",
      "48000/48000 [==============================] - 1s 25us/step - loss: 0.2363 - acc: 0.9323 - val_loss: 0.2345 - val_acc: 0.9322\n",
      "Epoch 47/100\n",
      "48000/48000 [==============================] - 1s 25us/step - loss: 0.2339 - acc: 0.9323 - val_loss: 0.2306 - val_acc: 0.9347\n",
      "Epoch 48/100\n",
      "48000/48000 [==============================] - 1s 27us/step - loss: 0.2314 - acc: 0.9335 - val_loss: 0.2300 - val_acc: 0.9358\n",
      "Epoch 49/100\n",
      "48000/48000 [==============================] - 1s 26us/step - loss: 0.2292 - acc: 0.9337 - val_loss: 0.2282 - val_acc: 0.9344\n",
      "Epoch 50/100\n",
      "48000/48000 [==============================] - 1s 27us/step - loss: 0.2272 - acc: 0.9342 - val_loss: 0.2255 - val_acc: 0.9363\n",
      "Epoch 51/100\n",
      "48000/48000 [==============================] - 1s 26us/step - loss: 0.2249 - acc: 0.9346 - val_loss: 0.2262 - val_acc: 0.9348\n",
      "Epoch 52/100\n",
      "48000/48000 [==============================] - 1s 30us/step - loss: 0.2222 - acc: 0.9356 - val_loss: 0.2219 - val_acc: 0.9375\n",
      "Epoch 53/100\n",
      "48000/48000 [==============================] - 2s 34us/step - loss: 0.2198 - acc: 0.9373 - val_loss: 0.2183 - val_acc: 0.9388\n",
      "Epoch 54/100\n",
      "48000/48000 [==============================] - 1s 26us/step - loss: 0.2176 - acc: 0.9381 - val_loss: 0.2166 - val_acc: 0.9388\n",
      "Epoch 55/100\n",
      "48000/48000 [==============================] - 1s 25us/step - loss: 0.2155 - acc: 0.9377 - val_loss: 0.2174 - val_acc: 0.9394\n",
      "Epoch 56/100\n",
      "48000/48000 [==============================] - 1s 25us/step - loss: 0.2134 - acc: 0.9389 - val_loss: 0.2184 - val_acc: 0.9395\n",
      "Epoch 57/100\n",
      "48000/48000 [==============================] - 1s 25us/step - loss: 0.2112 - acc: 0.9389 - val_loss: 0.2116 - val_acc: 0.9415\n",
      "Epoch 58/100\n",
      "48000/48000 [==============================] - 1s 25us/step - loss: 0.2090 - acc: 0.9398 - val_loss: 0.2083 - val_acc: 0.9426\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48000/48000 [==============================] - 1s 28us/step - loss: 0.2066 - acc: 0.9408 - val_loss: 0.2067 - val_acc: 0.9432\n",
      "Epoch 60/100\n",
      "48000/48000 [==============================] - 1s 28us/step - loss: 0.2043 - acc: 0.9414 - val_loss: 0.2049 - val_acc: 0.9443\n",
      "Epoch 61/100\n",
      "48000/48000 [==============================] - 1s 27us/step - loss: 0.2023 - acc: 0.9425 - val_loss: 0.2069 - val_acc: 0.9430\n",
      "Epoch 62/100\n",
      "48000/48000 [==============================] - 1s 27us/step - loss: 0.2002 - acc: 0.9427 - val_loss: 0.2036 - val_acc: 0.9444\n",
      "Epoch 63/100\n",
      "48000/48000 [==============================] - 1s 29us/step - loss: 0.1980 - acc: 0.9427 - val_loss: 0.2007 - val_acc: 0.9450\n",
      "Epoch 64/100\n",
      "48000/48000 [==============================] - 1s 26us/step - loss: 0.1957 - acc: 0.9433 - val_loss: 0.2045 - val_acc: 0.9427\n",
      "Epoch 65/100\n",
      "48000/48000 [==============================] - 1s 26us/step - loss: 0.1935 - acc: 0.9443 - val_loss: 0.1964 - val_acc: 0.9469\n",
      "Epoch 66/100\n",
      "48000/48000 [==============================] - 1s 26us/step - loss: 0.1913 - acc: 0.9451 - val_loss: 0.1970 - val_acc: 0.9463\n",
      "Epoch 67/100\n",
      "48000/48000 [==============================] - 1s 26us/step - loss: 0.1896 - acc: 0.9458 - val_loss: 0.1972 - val_acc: 0.9455\n",
      "Epoch 68/100\n",
      "48000/48000 [==============================] - 1s 27us/step - loss: 0.1877 - acc: 0.9460 - val_loss: 0.1930 - val_acc: 0.9477\n",
      "Epoch 69/100\n",
      "48000/48000 [==============================] - 1s 27us/step - loss: 0.1854 - acc: 0.9466 - val_loss: 0.1892 - val_acc: 0.9495\n",
      "Epoch 70/100\n",
      "48000/48000 [==============================] - 1s 27us/step - loss: 0.1832 - acc: 0.9470 - val_loss: 0.1891 - val_acc: 0.9492\n",
      "Epoch 71/100\n",
      "48000/48000 [==============================] - 1s 27us/step - loss: 0.1812 - acc: 0.9475 - val_loss: 0.1868 - val_acc: 0.9480\n",
      "Epoch 72/100\n",
      "48000/48000 [==============================] - 1s 27us/step - loss: 0.1797 - acc: 0.9481 - val_loss: 0.1860 - val_acc: 0.9488\n",
      "Epoch 73/100\n",
      "48000/48000 [==============================] - 1s 28us/step - loss: 0.1774 - acc: 0.9487 - val_loss: 0.1833 - val_acc: 0.9495\n",
      "Epoch 74/100\n",
      "48000/48000 [==============================] - 1s 26us/step - loss: 0.1756 - acc: 0.9489 - val_loss: 0.1835 - val_acc: 0.9503\n",
      "Epoch 75/100\n",
      "48000/48000 [==============================] - 1s 26us/step - loss: 0.1739 - acc: 0.9500 - val_loss: 0.1811 - val_acc: 0.9500\n",
      "Epoch 76/100\n",
      "48000/48000 [==============================] - 1s 27us/step - loss: 0.1719 - acc: 0.9504 - val_loss: 0.1798 - val_acc: 0.9516\n",
      "Epoch 77/100\n",
      "48000/48000 [==============================] - 1s 27us/step - loss: 0.1703 - acc: 0.9505 - val_loss: 0.1785 - val_acc: 0.9504\n",
      "Epoch 78/100\n",
      "48000/48000 [==============================] - 1s 27us/step - loss: 0.1683 - acc: 0.9515 - val_loss: 0.1770 - val_acc: 0.9518\n",
      "Epoch 79/100\n",
      "48000/48000 [==============================] - 1s 26us/step - loss: 0.1663 - acc: 0.9518 - val_loss: 0.1755 - val_acc: 0.9513\n",
      "Epoch 80/100\n",
      "48000/48000 [==============================] - 1s 26us/step - loss: 0.1646 - acc: 0.9520 - val_loss: 0.1757 - val_acc: 0.9513\n",
      "Epoch 81/100\n",
      "48000/48000 [==============================] - 1s 26us/step - loss: 0.1632 - acc: 0.9527 - val_loss: 0.1736 - val_acc: 0.9524\n",
      "Epoch 82/100\n",
      "48000/48000 [==============================] - 1s 26us/step - loss: 0.1616 - acc: 0.9528 - val_loss: 0.1720 - val_acc: 0.9529\n",
      "Epoch 83/100\n",
      "48000/48000 [==============================] - 1s 26us/step - loss: 0.1596 - acc: 0.9532 - val_loss: 0.1710 - val_acc: 0.9522\n",
      "Epoch 84/100\n",
      "48000/48000 [==============================] - 1s 26us/step - loss: 0.1583 - acc: 0.9541 - val_loss: 0.1706 - val_acc: 0.9526\n",
      "Epoch 85/100\n",
      "48000/48000 [==============================] - 1s 26us/step - loss: 0.1563 - acc: 0.9546 - val_loss: 0.1708 - val_acc: 0.9533\n",
      "Epoch 86/100\n",
      "48000/48000 [==============================] - 1s 26us/step - loss: 0.1547 - acc: 0.9554 - val_loss: 0.1696 - val_acc: 0.9537\n",
      "Epoch 87/100\n",
      "48000/48000 [==============================] - 1s 28us/step - loss: 0.1532 - acc: 0.9559 - val_loss: 0.1678 - val_acc: 0.9533\n",
      "Epoch 88/100\n",
      "48000/48000 [==============================] - 1s 27us/step - loss: 0.1520 - acc: 0.9563 - val_loss: 0.1657 - val_acc: 0.9540\n",
      "Epoch 89/100\n",
      "48000/48000 [==============================] - 1s 26us/step - loss: 0.1503 - acc: 0.9568 - val_loss: 0.1654 - val_acc: 0.9541\n",
      "Epoch 90/100\n",
      "48000/48000 [==============================] - 1s 26us/step - loss: 0.1485 - acc: 0.9574 - val_loss: 0.1663 - val_acc: 0.9532\n",
      "Epoch 91/100\n",
      "48000/48000 [==============================] - 1s 26us/step - loss: 0.1472 - acc: 0.9577 - val_loss: 0.1611 - val_acc: 0.9553\n",
      "Epoch 92/100\n",
      "48000/48000 [==============================] - 1s 26us/step - loss: 0.1457 - acc: 0.9578 - val_loss: 0.1623 - val_acc: 0.9552\n",
      "Epoch 93/100\n",
      "48000/48000 [==============================] - 1s 26us/step - loss: 0.1440 - acc: 0.9588 - val_loss: 0.1615 - val_acc: 0.9558\n",
      "Epoch 94/100\n",
      "48000/48000 [==============================] - 1s 26us/step - loss: 0.1427 - acc: 0.9584 - val_loss: 0.1601 - val_acc: 0.9577\n",
      "Epoch 95/100\n",
      "48000/48000 [==============================] - 1s 25us/step - loss: 0.1416 - acc: 0.9592 - val_loss: 0.1565 - val_acc: 0.9561\n",
      "Epoch 96/100\n",
      "48000/48000 [==============================] - 1s 26us/step - loss: 0.1397 - acc: 0.9592 - val_loss: 0.1579 - val_acc: 0.9562\n",
      "Epoch 97/100\n",
      "48000/48000 [==============================] - 1s 25us/step - loss: 0.1386 - acc: 0.9601 - val_loss: 0.1538 - val_acc: 0.9580\n",
      "Epoch 98/100\n",
      "48000/48000 [==============================] - 1s 25us/step - loss: 0.1373 - acc: 0.9605 - val_loss: 0.1551 - val_acc: 0.9571\n",
      "Epoch 99/100\n",
      "48000/48000 [==============================] - 1s 25us/step - loss: 0.1356 - acc: 0.9611 - val_loss: 0.1553 - val_acc: 0.9557\n",
      "Epoch 100/100\n",
      "48000/48000 [==============================] - 1s 25us/step - loss: 0.1345 - acc: 0.9611 - val_loss: 0.1515 - val_acc: 0.9590\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(X_train,y_train,batch_size=batch_size,epochs=n_epoch,verbose=1,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 28us/step\n",
      "Summary:Loss over the test dataset:0.15,Accuracy 0.96\n"
     ]
    }
   ],
   "source": [
    "# 模型评估\n",
    "evaluation=model.evaluate(X_test,y_test,verbose=1)\n",
    "print(\"Summary:Loss over the test dataset:%.2f,Accuracy %.2f\" % (evaluation[0],evaluation[1]))\n",
    "# Summary:Loss over the test dataset:0.12,Accuracy 0.96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"264pt\" viewBox=\"0.00 0.00 119.00 264.00\" width=\"119pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 260)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-260 115,-260 115,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 1620654868352 -->\n",
       "<g class=\"node\" id=\"node1\"><title>1620654868352</title>\n",
       "<polygon fill=\"none\" points=\"0,-146.5 0,-182.5 111,-182.5 111,-146.5 0,-146.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"55.5\" y=\"-160.8\">dense_13: Dense</text>\n",
       "</g>\n",
       "<!-- 1620654268200 -->\n",
       "<g class=\"node\" id=\"node2\"><title>1620654268200</title>\n",
       "<polygon fill=\"none\" points=\"0,-73.5 0,-109.5 111,-109.5 111,-73.5 0,-73.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"55.5\" y=\"-87.8\">dense_14: Dense</text>\n",
       "</g>\n",
       "<!-- 1620654868352&#45;&gt;1620654268200 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>1620654868352-&gt;1620654268200</title>\n",
       "<path d=\"M55.5,-146.313C55.5,-138.289 55.5,-128.547 55.5,-119.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"59.0001,-119.529 55.5,-109.529 52.0001,-119.529 59.0001,-119.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1620655134088 -->\n",
       "<g class=\"node\" id=\"node3\"><title>1620655134088</title>\n",
       "<polygon fill=\"none\" points=\"0,-0.5 0,-36.5 111,-36.5 111,-0.5 0,-0.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"55.5\" y=\"-14.8\">dense_15: Dense</text>\n",
       "</g>\n",
       "<!-- 1620654268200&#45;&gt;1620655134088 -->\n",
       "<g class=\"edge\" id=\"edge3\"><title>1620654268200-&gt;1620655134088</title>\n",
       "<path d=\"M55.5,-73.3129C55.5,-65.2895 55.5,-55.5475 55.5,-46.5691\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"59.0001,-46.5288 55.5,-36.5288 52.0001,-46.5289 59.0001,-46.5288\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1620655134872 -->\n",
       "<g class=\"node\" id=\"node4\"><title>1620655134872</title>\n",
       "<polygon fill=\"none\" points=\"3.5,-219.5 3.5,-255.5 107.5,-255.5 107.5,-219.5 3.5,-219.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"55.5\" y=\"-233.8\">1620655134872</text>\n",
       "</g>\n",
       "<!-- 1620655134872&#45;&gt;1620654868352 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>1620655134872-&gt;1620654868352</title>\n",
       "<path d=\"M55.5,-219.313C55.5,-211.289 55.5,-201.547 55.5,-192.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"59.0001,-192.529 55.5,-182.529 52.0001,-192.529 59.0001,-192.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
